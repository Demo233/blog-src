---
layout: post
title: spark集群搭建
date: 2018-08-27 00:00:00
categories: 大数据
tags: Spark
---


这边使用VM创建3台cor1、cor2、cor4虚拟机，配置好网络、关闭防火墙之类的就不多详述、到spark官网下载程序包``spark-1.6.1-bin-hadoop2.6``

需要注意的是虚拟机内存不能分配的太小，不然会导致启动失败。(这边也在考虑再拓展个8G内存条了，可惜现在的内存条真的是很贵。。)

我打算在cor1上启动Master，在cor2和cor4上启动Worker。分配的内存分别为(1G,2G,2G)

## 概述

开始之前

这边在``/``目录下事先创建一个 ``/export/servers/``目录，该目录用于存放大数据相关的安装包、比如hadoop、hive、storm等等，方便管理。

同时创建一个专门的用户``hadoop``，在使用这方面东西的时候切换到该角色。

不要忘记修改 ``/export/servers/`` 目录的权限组

### 1.解压

使用下面命令解压

> $ tar -zxvf spark-1.6.1-bin-hadoop2.6.tgz -C /export/servers/

### 2.配置

配置``spark-env.sh``文件,在尾部追加下面代码

```shell
export JAVA_HOME=/usr/local/jdk1.8.0_161/
export SPARK_MASTER_IP=spark1
export SPARK_MASTER_PORT=7077
```

将worker所在机器的ip写在``slaves``文件中

```shell
cor2
cor4
```

### 3.分发

将配置好的spark分发到cor2、cor4机器上

> $ scp -r spark-1.6.1/ hadoop@cor2:/export/servers

### 4.运行

> $ /sbin/start-all.sh

启动后可以使用 127.0.0.1:8080访问 来访问sparkweb端

### 5.spark-shell

spark为编程人员专门提供了``spark-shell``，该功能可以使开发者以终端形式编写scala，进行代码调试，十分方便

运行``spark-shell``

> $ bin/spark-shell \-\-master spark://cor1:7077 \-\-executor-memory 512m \-\-total-executor-cores 2

参数 | 说明
----|-----
\-\-master spark://cor1:7077 | 指定Master地址
\-\-executor-memory 512m | 指定每个Worker可用内存为512m
\-\-total-executor-cores | 指定整个集群使用cpu核数



### 6.写个简单的wordcount

启动hdfs，上传wordcount.txt到hdfs上

> $ sc.textFile("hdfs://cor1:9000/wordcount.txt").flatMap(_.split("&nbsp;")).map((\_,1)).reduceByKey(\_+\_).saveAsTextFile("hdfs://cor1:9000/out")